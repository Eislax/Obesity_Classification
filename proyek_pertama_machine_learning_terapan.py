# -*- coding: utf-8 -*-
"""Proyek_Pertama_Machine_Learning_Terapan.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XnPpZgdZk6kwrKx-mrc_pXvCkeW6PibE

# Proyek Machine Learning Terapan : [Obesity classification]
- **Nama:** Muhammad Rafi Ilham
- **Email:** mrafilham83@gmail.com
- **Dataset:** https://www.kaggle.com/datasets/adeniranstephen/obesity-prediction-dataset?select=ObesityDataSet_raw_and_data_sinthetic.csv

# **1. IMPORT LIBRARY YANG DIBUTUHKAN**

Melakukan import semua library yang dibutuhkan
"""

# Import library yang diperlukan
import pandas as pd  # Untuk manipulasi data
import numpy as np  # Untuk operasi numerik
import seaborn as sns  # Untuk visualisasi data
import matplotlib.pyplot as plt  # Untuk visualisasi data
import collections
from collections import Counter

# Library untuk preprocessing
from sklearn.model_selection import train_test_split  # Untuk split data
from sklearn.preprocessing import StandardScaler, LabelEncoder  # Untuk scaling dan encoding
from sklearn.impute import SimpleImputer  # Untuk menangani missing values
from sklearn.feature_selection import SelectKBest, f_classif

# Library untuk modeling
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import classification_report, confusion_matrix  # Untuk evaluasi model

"""# **2. DATA LOADING**

Data Loading merupakan tahap untuk memuat dataset yang akan digunakan agar dataset lebih mudah dipahami.

## MEMUAT DATASET
"""

# Load dataset
data = pd.read_csv('ObesityDataSet_raw_and_data_sinthetic.csv')

# Informasi umum tentang dataset
print("=== Informasi Umum Dataset ===")
data.info()

# Menampilkan lima baris pertama dataset
print("Dataset berhasil dimuat.")
print(data.head())

"""# **3. Data Understanding**

## Deskripsi Statistik

Fungsi .describe() digunakan untuk mendapatkan statistik deskriptif (mean, min, max, dll.) dari fitur numerik dalam dataset.
Ini membantu memahami distribusi data numerik.
"""

data.describe()

"""## Penyesuaian Nama Kolom dan Konversi nilai

Pada bagian ini, nama kolom diubah agar lebih deskriptif dan mudah dipahami.
Transformasi seperti .replace() dilakukan untuk membersihkan teks (mengganti underscore _ dengan spasi).
Langkah ini membantu dalam mempersiapkan dataset untuk analisis lebih lanjut.
"""

data.columns

data.columns = ['Gender', 'Age', 'Height', 'Weight', 'Family History with Overweight',
       'Frequent consumption of high caloric food', 'Frequency of consumption of vegetables', 'Number of main meals', 'Consumption of food between meals', 'Smoke', 'Consumption of water daily', 'Calories consumption monitoring', 'Physical activity frequency', 'Time using technology devices',
       'Consumption of alcohol', 'Transportation used', 'Obesity']

data

"""Tinggi badan dikonversi dari meter ke sentimeter untuk konsistensi.
Nilai-nilai numerik seperti Height, Weight, dan Age dibulatkan ke satu desimal untuk kemudahan interpretasi.
Ini adalah langkah pra-pemrosesan untuk memastikan data dalam format yang sesuai.
"""

data['Obesity'] = data['Obesity'].apply(lambda x: x.replace('_', ' '))
data['Transportation used'] = data['Transportation used'].apply(lambda x: x.replace('_', ' '))
data['Height'] = data['Height']*100
data['Height'] = data['Height'].round(1)
data['Weight'] = data['Weight'].round(1)
data['Age'] = data['Age'].round(1)
data

"""# **4. Exploratory Data Analysis (EDA)**

Menganalisis dataset secara mendalam untuk memahami pola, tren, dan hubungan antar variabel. EDA membantu kita mengidentifikasi fitur penting, distribusi data, dan potensi masalah seperti missing values atau outliers.

## Analisis Distribusi Fitur Numerik

Memeriksa nilai minimum, maksimum, dan unik dari fitur numerik.
Hasilnya:
Rentang nilai untuk setiap fitur numerik.
Nilai-nilai unik yang ada dalam kolom tersebut.
Contoh:
Frequency of consumption of vegetables: Rentang nilai 1–3.
Time using technology devices: Rentang nilai 0–2.
"""

for x in ['Frequency of consumption of vegetables', 'Number of main meals', 'Consumption of water daily', 'Physical activity frequency', 'Time using technology devices']:
    value = np.array(data[x])
    print(x,':', 'min:', np.min(value), 'max:', np.max(value))

"""## Pembulatan dan Identifikasi Nilai Unik

Membulatkan nilai numerik agar lebih mudah dipahami dan menampilkan nilai unik dalam setiap kolom.
Hasilnya:
Nilai unik untuk setiap fitur numerik.
Tipe data (dtype) dari setiap kolom.
Contoh:
Frequency of consumption of vegetables: Nilai unik [2, 3, 1].
Number of main meals: Nilai unik [3, 1, 4, 2].
"""

for x in ['Frequency of consumption of vegetables', 'Number of main meals',
          'Consumption of water daily', 'Physical activity frequency',
          'Time using technology devices']:
    data[x] = data[x].apply(round)
    value = np.array(data[x])
    print(x, ':', 'min:', np.min(value), 'max:', np.max(value), data[x].dtype)
    print(data[x].unique())

"""## Mapping Nilai Kategorikal

Mengganti nilai numerik dengan label kategorikal yang lebih bermakna.
Contoh hasil mapping:
Frequency of consumption of vegetables: Nilai 2 diubah menjadi Sometimes.
Consumption of water daily: Nilai 3 diubah menjadi More than 2 L.
"""

mapping0 = {1:'Never', 2:'Sometimes', 3:'Always'}
mapping1 = {1: '1', 2:'2' , 3: '3', 4: '3+'}
mapping2 = {1: 'Less than a liter', 2:'Between 1 and 2 L', 3:'More than 2 L'}
mapping3 = {0: 'I do not have', 1: '1 or 2 days', 2: '2 or 4 days', 3: '4 or 5 days'}
mapping4 = {0: '0–2 hours', 1: '3–5 hours', 2: 'More than 5 hours'}

data['Frequency of consumption of vegetables'] = data['Frequency of consumption of vegetables'].replace(mapping0)
data['Number of main meals'] = data['Number of main meals'].replace(mapping1)
data['Consumption of water daily'] = data['Consumption of water daily'].replace(mapping2)
data['Physical activity frequency'] = data['Physical activity frequency'].replace(mapping3)
data['Time using technology devices'] = data['Time using technology devices'].replace(mapping4)

"""## Visualisasi Distribusi Tinggi dan Berat Badan"""

sns.set()
fig = plt.figure(figsize=(20,10))
plt.subplot(1, 2, 1)
sns.boxplot(x='Gender', y='Height', data=data)
plt.subplot(1, 2, 2)
sns.boxplot(x='Gender', y='Weight', data=data)

"""## Hubungan Antara Tinggi dan Berat Badan"""

sns.set()
g = sns.jointplot(
    x="Height",  # Nama kolom untuk sumbu x
    y="Weight",  # Nama kolom untuk sumbu y
    data=data,   # Dataset yang digunakan
    kind="reg",  # Jenis plot (regresi)
    truncate=False,
    xlim=(125, 200),  # Batas sumbu x
    ylim=(35, 180),   # Batas sumbu y
    color="m",        # Warna plot
    height=10         # Tinggi plot
)
g.set_axis_labels("Height (cm)", "Weight (kg)")  # Label sumbu

# Plot dengan pemisahan berdasarkan gender
g = sns.lmplot(
    x="Height",       # Nama kolom untuk sumbu x
    y="Weight",       # Nama kolom untuk sumbu y
    hue="Gender",     # Pemisahan berdasarkan gender
    height=10,        # Tinggi plot
    data=data         # Dataset yang digunakan
)
g.set_axis_labels("Height (cm)", "Weight (kg)")  # Label sumbu

"""Menunjukkan hubungan linier antara tinggi dan berat badan.
Hasilnya:
Plot regresi menunjukkan bahwa semakin tinggi seseorang, semakin berat badannya.
Garis plot pada perempuan lebih curam, menunjukkan variasi berat badan yang lebih besar.

## Analisis Distribusi Status Obesitas
"""

c = Counter(data['Obesity'])
print(c)

fig = plt.figure(figsize=(8,8))
plt.pie([float(c[v]) for v in c], labels=[str(k) for k in c], autopct=None)
plt.title('Weight Category')
plt.tight_layout()

filt = data['Gender'] == 'Male'
c_m = Counter(data.loc[filt, 'Obesity'])
print(c_m)
c_f = Counter(data.loc[~filt, 'Obesity'])
print(c_f)

fig = plt.figure(figsize=(20,8))
plt.subplot(1, 2, 1)
plt.pie([float(c_m[v]) for v in c_m], labels=[str(k) for k in c_m], autopct=None)
plt.title('Weight Category of Male')
plt.tight_layout()

plt.subplot(1, 2, 2)
plt.pie([float(c_f[v]) for v in c_f], labels=[str(k) for k in c_f], autopct=None)
plt.title('Weight Category of Female')
plt.tight_layout()

"""Menganalisis distribusi status obesitas secara keseluruhan dan berdasarkan gender.
Hasilnya:
Perempuan memiliki proporsi yang lebih besar untuk kategori Obesity Type III dan Insufficient Weight.
Laki-laki memiliki proporsi yang lebih besar untuk kategori Obesity Type II.

## Visualisasi Kebiasaan Makan dan Aktivitas Fisik
"""

for a in data.columns[4:-1]:
    counts = data[a].value_counts()
    values = counts.index.to_list()
    counts = counts.to_list()

    plt.figure(figsize=(12,5))
    ax = sns.barplot(x=values, y=counts)

    plt.title(a)
    plt.xticks(rotation=45)
    print(a, values, counts)

"""Memvisualisasikan distribusi variabel kategorikal seperti Family History with Overweight, Frequent consumption of high caloric food, dll.
Hasilnya:
Sebagian besar individu memiliki riwayat keluarga dengan obesitas (yes).
Konsumsi air harian sebagian besar berada pada kategori Between 1 and 2 L.

# **KESIMPULAN EDA:**
* Analisis Distribusi Fitur Numerik: Memahami rentang nilai dan distribusi fitur numerik.
* Pembulatan dan Identifikasi Nilai Unik: Membulatkan nilai numerik dan menampilkan nilai unik.
* Mapping Nilai Kategorikal: Mengganti nilai numerik dengan label kategorikal yang lebih deskriptif.
* Visualisasi Tinggi dan Berat Badan: Membandingkan distribusi tinggi dan berat badan berdasarkan gender.
* Hubungan Tinggi dan Berat Badan: Menunjukkan hubungan linier antara tinggi dan berat badan.
* Analisis Status Obesitas: Memahami distribusi status obesitas secara keseluruhan dan berdasarkan gender.
* Visualisasi Kebiasaan Makan dan Aktivitas Fisik: Memahami pola kebiasaan makan dan aktivitas fisik.

# **5. Data Preparation**

Mempersiapkan dataset agar siap digunakan untuk pemodelan machine learning. Ini mencakup penanganan missing values, encoding variabel kategorikal, feature scaling, dan split data.

## Penanganan Missing Values

Memastikan tidak ada nilai kosong dalam dataset yang dapat memengaruhi performa model.
"""

# Cek missing values
print(data.isnull().sum())

data.head()

"""## Encoding Variabel Kategorikal

Tujuan utama dari langkah ini adalah untuk mempersiapkan dataset agar dapat diproses oleh algoritma machine learning, karena sebagian besar algoritma hanya dapat bekerja dengan data numerik.
"""

# Mapping untuk kolom 'yes/no'
new_yesno = {'yes': 1, 'no': 0}
columns_to_encode = [
    'Family History with Overweight',
    'Frequent consumption of high caloric food',
    'Smoke',
    'Calories consumption monitoring'
]

for col in columns_to_encode:
    data[col] = data[col].replace(new_yesno)

# Mapping manual untuk kolom lainnya
mapping_gender = {'Female': 0, 'Male': 1}
mapping_vegetables = {'Never': 0, 'Sometimes': 1, 'Always': 2}
mapping_meals = {'1': 1, '2': 2, '3': 3, '3+': 4}
mapping_water = {
    'Less than a liter': 0,
    'Between 1 and 2 L': 1,
    'More than 2 L': 2
}
mapping_physical_activity = {
    'I do not have': 0,
    '1 or 2 days': 1,
    '2 or 4 days': 2,
    '4 or 5 days': 3
}
mapping_tech_usage = {
    '0–2 hours': 0,
    '3–5 hours': 1,
    'More than 5 hours': 2
}
mapping_alcohol = {
    'no': 0,
    'Sometimes': 1,
    'Frequently': 2,
    'Always': 3
}

# Apply mapping
data['Gender'] = data['Gender'].replace(mapping_gender)
data['Frequency of consumption of vegetables'] = data['Frequency of consumption of vegetables'].replace(mapping_vegetables)
data['Number of main meals'] = data['Number of main meals'].replace(mapping_meals)
data['Consumption of water daily'] = data['Consumption of water daily'].replace(mapping_water)
data['Physical activity frequency'] = data['Physical activity frequency'].replace(mapping_physical_activity)
data['Time using technology devices'] = data['Time using technology devices'].replace(mapping_tech_usage)
data['Consumption of alcohol'] = data['Consumption of alcohol'].replace(mapping_alcohol)

# One-Hot Encoding untuk kolom 'Transportation used' dan 'Consumption of food between meals'
data = pd.get_dummies(data, columns=['Transportation used', 'Consumption of food between meals'], drop_first=True)

# Encode target variable 'Obesity' menggunakan LabelEncoder
from sklearn.preprocessing import LabelEncoder
label_encoder = LabelEncoder()
data['Obesity'] = label_encoder.fit_transform(data['Obesity'])

# Tampilkan mapping antara kategori asli dan nilai numerik
print("Mapping LabelEncoder untuk 'Obesity':")
for index, category in enumerate(label_encoder.classes_):
    print(f"{index} -> {category}")

data

"""* Kolom biner (Yes/No): Kolom-kolom seperti Family History with Overweight, Frequent consumption of high caloric food, Smoke, dan Calories consumption monitoring memiliki dua nilai unik (yes dan no).
* Tujuan: Mengganti nilai kategorikal (yes dan no) dengan nilai numerik (1 dan 0) untuk menyederhanakan data.
* Manfaat: Algoritma machine learning tidak dapat memproses teks secara langsung, jadi konversi ini diperlukan. Selain itu, nilai biner lebih efisien dalam komputasi.

* Kolom dengan lebih dari dua kategori: Kolom-kolom seperti Gender, Frequency of consumption of vegetables, Number of main meals, dll., memiliki lebih dari dua kategori.
* Tujuan: Mengganti nilai-nilai kategorikal dengan nilai numerik berdasarkan urutan logis atau tingkatannya (ordinal encoding).
* Manfaat:
Ordinal Encoding: Nilai numerik mencerminkan urutan logis antara kategori. Misalnya, Never < Sometimes < Always diwakili sebagai 0, 1, 2.
Efisiensi Komputasi: Algoritma machine learning lebih mudah memproses angka daripada teks.

* Kolom dengan banyak kategori tanpa urutan logis: Kolom seperti Transportation used dan Consumption of food between meals memiliki banyak kategori (misalnya, Public Transportation, Walking, Bike, dll.) yang tidak memiliki urutan logis.
* Tujuan: Menggunakan One-Hot Encoding untuk membuat kolom baru untuk setiap kategori.
* Manfaat:
Menghindari Masalah Ordinalitas: One-hot encoding menghindari asumsi bahwa ada hubungan ordinal antara kategori (misalnya, Public Transportation tidak "lebih besar" dari Walking).
Drop First: Parameter drop_first=True digunakan untuk menghindari dummy variable trap , yaitu masalah multikolinearitas yang terjadi ketika satu variabel dapat diprediksi dari variabel lainnya.

* Target Variable (Obesity): Kolom target Obesity memiliki beberapa kategori seperti Normal Weight, Overweight Level I, Obesity Type III, dll.
* Tujuan: Mengubah nilai-nilai kategorikal menjadi numerik menggunakan LabelEncoder.
* Manfaat:
Klasifikasi Machine Learning: Algoritma klasifikasi membutuhkan target variable dalam bentuk numerik untuk melakukan prediksi.
Kepraktisan: LabelEncoder memberikan nilai numerik unik untuk setiap kategori (misalnya, Normal Weight = 0, Overweight Level I = 1, dst.).

## Feature Scaling

Feature Selection adalah proses memilih subset fitur (variabel) yang paling relevan dari dataset untuk digunakan dalam pemodelan machine learning. Tujuan utamanya adalah:

Mengurangi dimensi data untuk meningkatkan efisiensi komputasi.
Menghilangkan fitur yang tidak relevan atau redundan, yang dapat menyebabkan noise dalam model.
Meningkatkan performa model dengan fokus pada fitur yang memiliki hubungan kuat dengan variabel target.

ANOVA F-test adalah metode statistik yang digunakan untuk mengevaluasi hubungan antara setiap fitur numerik dengan variabel target kategorikal. Alasan penggunaannya adalah:

Statistik F: Nilai F mengukur seberapa besar variasi antar kelompok (kategori target) dibandingkan dengan variasi di dalam kelompok. Semakin tinggi nilai F, semakin kuat hubungan antara fitur tersebut dengan target.
P-value: Mengukur signifikansi statistik dari hubungan tersebut. Fitur dengan p-value rendah (<0.05) dianggap memiliki hubungan yang signifikan dengan target.

Memilih fitur yang paling relevan berdasarkan metode statistik seperti ANOVA F-test.
Hasilnya:
Fitur-fitur dengan korelasi tinggi terhadap target variabel (Obesity) akan dipilih.
"""

# Pilih fitur terbaik berdasarkan ANOVA F-test
X = data.drop('Obesity', axis=1)  # Features
y = data['Obesity']  # Target

# Feature selection menggunakan SelectKBest
selector = SelectKBest(score_func=f_classif, k=10)  # Pilih 10 fitur terbaik
X_selected = selector.fit_transform(X, y)

# Tampilkan fitur yang dipilih
selected_features = X.columns[selector.get_support()]
print("Fitur yang dipilih:", selected_features)

"""Penjelasan Fitur yang Dipilih:
Berikut adalah interpretasi dari fitur-fitur yang dipilih:

1. Gender:
Variabel ini mungkin memiliki hubungan dengan obesitas karena perbedaan metabolisme antara laki-laki dan perempuan.
2. Age:
Usia dapat memengaruhi risiko obesitas karena perubahan gaya hidup dan metabolisme seiring bertambahnya usia.
3. Height (Tinggi Badan):
Tinggi badan berkorelasi dengan berat badan dan indeks massa tubuh (BMI), yang merupakan faktor penting dalam klasifikasi obesitas.
4. Weight (Berat Badan):
Berat badan adalah indikator langsung dari status obesitas, sehingga wajar jika fitur ini dipilih.
5. Family History with Overweight:
Riwayat keluarga dengan kelebihan berat badan dapat menjadi prediktor kuat untuk risiko obesitas karena faktor genetik.
6. Frequent consumption of high caloric food:
Konsumsi makanan tinggi kalori secara rutin dapat meningkatkan risiko obesitas.
7. Frequency of consumption of vegetables:
Konsumsi sayuran sering dikaitkan dengan pola makan sehat, yang dapat memengaruhi status obesitas.
8. Consumption of alcohol:
Konsumsi alkohol dapat berkontribusi pada asupan kalori tambahan, yang berpotensi memengaruhi status obesitas.
9. Consumption of food between meals_Frequently:
Makan di antara waktu makan utama secara rutin dapat meningkatkan asupan kalori harian.
10. Consumption of food between meals_Sometimes:
Pola makan ini mungkin memiliki hubungan moderat dengan risiko obesitas dibandingkan dengan "Frequently" atau "Never."

Fitur-fitur yang dipilih memiliki hubungan statistik yang signifikan dengan variabel target (Obesity) berdasarkan ANOVA F-test. Alasan spesifiknya adalah:

Variabel Numerik: Fitur seperti Age, Height, dan Weight memiliki hubungan linier yang jelas dengan status obesitas.
Variabel Kategorikal: Fitur seperti Family History with Overweight dan Frequent consumption of high caloric food mencerminkan faktor risiko yang kuat untuk obesitas.
One-Hot Encoded Features: Fitur seperti Consumption of food between meals_Frequently dan Consumption of food between meals_Sometimes menunjukkan pola kebiasaan makan yang relevan dengan status obesitas.

## Split Dataset

Membagi dataset menjadi training set (80%) dan testing set (20%).
Hasilnya:
X_train dan y_train digunakan untuk melatih model.
X_test dan y_test digunakan untuk evaluasi model.
"""

# Split dataset
X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)

"""# **6. Modeling**

Melatih model menggunakan algoritma seperti RandomForestClassifier, GradientBoostingClassifier, dan KNeighborsClassifier.
Hasilnya:
Evaluasi model menggunakan classification report dan confusion matrix.

* RandomForestClassifier dipilih karena kemampuannya menangani dataset dengan fitur campuran (numerik dan kategorikal) serta hubungan non-linear antar variabel, yang sering ditemui dalam kasus seperti ini. Random Forest juga stabil terhadap noise dan outliers, sehingga cocok untuk dataset dengan banyak fitur setelah tahap feature selection.
* GradientBoostingClassifier digunakan karena algoritma ini membangun model secara iteratif dengan memperbaiki kesalahan dari model sebelumnya, membuatnya sangat efektif dalam menangkap pola kompleks dalam data. Algoritma ini juga lebih sensitif terhadap ketidakseimbangan kelas minoritas, seperti beberapa kelas obesitas yang memiliki jumlah sampel lebih sedikit.
* KNeighborsClassifier dipilih karena sifatnya yang sederhana namun efektif untuk dataset yang telah melalui preprocessing seperti scaling. KNN bekerja berdasarkan jarak antar titik data, sehingga sangat bergantung pada kualitas preprocessing, yang dalam hal ini sudah dilakukan dengan baik melalui normalisasi fitur.
"""

# Inisialisasi model
models = {
    "RandomForest": RandomForestClassifier(random_state=42),
    "GradientBoosting": GradientBoostingClassifier(random_state=42),
    "KNeighbors": KNeighborsClassifier()
}

# Train dan evaluasi model
for name, model in models.items():
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)

    print(f"=== {name} ===")
    print(classification_report(y_test, y_pred))
    sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='Blues')
    plt.title(f'Confusion Matrix - {name}')
    plt.show()

"""# **7. Evaluation**

1. Akurasi (Accuracy)
* Definisi: Akurasi adalah proporsi prediksi yang benar dibandingkan dengan total jumlah prediksi.

* Rumus: $$
\text{Accuracy} = \frac{\text{True Positives} + \text{True Negatives}}{\text{Total Predictions}}
$$

* Interpretasi:
Akurasi mengukur seberapa sering model membuat prediksi yang benar secara keseluruhan. Misalnya, jika akurasi adalah 95%, itu berarti 95% dari semua prediksi yang dibuat oleh model adalah benar.

2. Precision
* Definisi:
Precision adalah proporsi prediksi positif yang benar dibandingkan dengan total prediksi positif.

* Rumus: $$
\text{Precision} = \frac{\text{True Positives}}{\text{True Positives} + \text{False Positives}}
$$

* Interpretasi:
Precision mengukur seberapa "percaya diri" model dalam memprediksi suatu kelas tertentu. Misalnya, jika precision untuk kelas Obesity Type III adalah 1.00, itu berarti setiap kali model memprediksi kelas ini, prediksinya selalu benar.

3. Recall (Sensitivitas)
* Definisi:
Recall adalah proporsi kasus positif aktual yang berhasil diidentifikasi oleh model.

* Rumus: $$
\text{Recall} = \frac{\text{True Positives}}{\text{True Positives} + \text{False Negatives}}
$$

* Interpretasi:
Recall mengukur kemampuan model untuk mengidentifikasi semua kasus positif. Misalnya, jika recall untuk kelas Insufficient Weight adalah 0.95, itu berarti model berhasil mengidentifikasi 95% dari semua kasus Insufficient Weight.

4. F1-Score
Definisi:
* F1-Score adalah rata-rata harmonik antara precision dan recall.

* Rumus: $$
\text{F1-Score} = 2 \cdot \frac{\text{Precision} \cdot \text{Recall}}{\text{Precision} + \text{Recall}}
$$

* Interpretasi:
F1-Score memberikan gambaran seimbang antara precision dan recall. Misalnya, jika F1-Score untuk kelas Overweight Level I adalah 0.93, itu berarti model memiliki keseimbangan yang baik antara precision dan recall untuk kelas tersebut.

5. Macro Average
* Definisi:
Macro average adalah rata-rata dari precision, recall, dan f1-score untuk semua kelas tanpa mempertimbangkan distribusi kelas.

* Rumus: $$
\text{Macro Avg} = \frac{1}{N} \sum_{i=1}^{N} \text{Metric}_i
$$

* Interpretasi:
Macro avg memberikan gambaran umum tentang performa model di semua kelas, terlepas dari ukuran kelas. Misalnya, jika macro avg precision adalah 0.94, itu berarti rata-rata precision untuk semua kelas adalah 94%.

6. Weighted Average
* Definisi:
Weighted average adalah rata-rata dari precision, recall, dan f1-score untuk semua kelas dengan mempertimbangkan distribusi kelas.

* Rumus: $$
\text{Weighted Avg} = \frac{\sum_{i=1}^{N} (\text{Support}_i \cdot \text{Metric}_i)}{\sum_{i=1}^{N} \text{Support}_i}
$$

* Interpretasi:
Weighted avg lebih fokus pada kelas-kelas dengan jumlah sampel yang lebih besar. Misalnya, jika weighted avg recall adalah 0.95, itu berarti model memiliki performa recall yang baik untuk kelas-kelas mayoritas.

Membandingkan performa model berdasarkan akurasi.
Hasilnya:
Model dengan akurasi tertinggi dipilih sebagai model terbaik.
"""

# Bandingkan hasil model
results = {}
for name, model in models.items():
    y_pred = model.predict(X_test)

    # Ambil classification report sebagai dictionary
    report = classification_report(y_test, y_pred, output_dict=True)

    # Simpan akurasi, precision, recall, f1-score, dan macro avg
    results[name] = {
        'Accuracy': report['accuracy'],
        'Precision (Macro Avg)': report['macro avg']['precision'],
        'Recall (Macro Avg)': report['macro avg']['recall'],
        'F1-Score (Macro Avg)': report['macro avg']['f1-score']
    }

# Tampilkan hasil dalam bentuk DataFrame
results_df = pd.DataFrame(results).T
print(results_df)

# Pilih model terbaik
best_model = results_df['Accuracy'].idxmax()
print(f"Model terbaik berdasarkan akurasi: {best_model}")